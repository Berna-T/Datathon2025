{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31c8b8c1",
      "metadata": {
        "id": "31c8b8c1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 50)\n",
        "pd.set_option(\"display.max_rows\", 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12ad64e8",
      "metadata": {
        "id": "12ad64e8"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "sample_submission = pd.read_csv(\"sample_submission.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ff9af02",
      "metadata": {
        "id": "2ff9af02"
      },
      "outputs": [],
      "source": [
        "train = train.drop_duplicates()\n",
        "test = test.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7a10ff3",
      "metadata": {
        "id": "a7a10ff3"
      },
      "outputs": [],
      "source": [
        "train[\"event_time\"] = pd.to_datetime(train[\"event_time\"])\n",
        "test[\"event_time\"] = pd.to_datetime(test[\"event_time\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f4015e7",
      "metadata": {
        "id": "9f4015e7"
      },
      "outputs": [],
      "source": [
        "def extract_datetime_features(df, datetime_cols):\n",
        "    for col in datetime_cols:\n",
        "        # Temel bileşenler\n",
        "        df[f\"{col}_year\"] = df[col].dt.year\n",
        "        df[f\"{col}_month\"] = df[col].dt.month\n",
        "        df[f\"{col}_day\"] = df[col].dt.day\n",
        "        df[f\"{col}_weekday\"] = df[col].dt.dayofweek\n",
        "        df[f\"{col}_dayofyear\"] = df[col].dt.dayofyear\n",
        "        df[f\"{col}_quarter\"] = df[col].dt.quarter\n",
        "        df[f\"{col}_hour\"] = df[col].dt.hour\n",
        "        df[f\"{col}_minute\"] = df[col].dt.minute\n",
        "        df[f\"{col}_second\"] = df[col].dt.second\n",
        "\n",
        "        # Boolean özellikler\n",
        "        df[f\"{col}_is_weekend\"] = df[col].dt.dayofweek >= 5\n",
        "        df[f\"{col}_is_month_start\"] = df[col].dt.is_month_start\n",
        "        df[f\"{col}_is_month_end\"] = df[col].dt.is_month_end\n",
        "        df[f\"{col}_is_quarter_start\"] = df[col].dt.is_quarter_start\n",
        "        df[f\"{col}_is_quarter_end\"] = df[col].dt.is_quarter_end\n",
        "        df[f\"{col}_is_year_start\"] = df[col].dt.is_year_start\n",
        "        df[f\"{col}_is_year_end\"] = df[col].dt.is_year_end\n",
        "        df[f\"{col}_after_15\"] = df[col].dt.day > 15\n",
        "\n",
        "        # Cyclical encoding (saat için)\n",
        "        df[f\"{col}_hour_sin\"] = np.sin(2 * np.pi * df[col].dt.hour / 24)\n",
        "        df[f\"{col}_hour_cos\"] = np.cos(2 * np.pi * df[col].dt.hour / 24)\n",
        "\n",
        "        df[f\"{col}_weekday_sin\"] = np.sin(2 * np.pi * df[col].dt.dayofweek / 7)\n",
        "        df[f\"{col}_weekday_cos\"] = np.cos(2 * np.pi * df[col].dt.dayofweek / 7)\n",
        "\n",
        "    return df\n",
        "\n",
        "def extract_features(df_train):\n",
        "    df_train[\"buy_ratio\"] = df_train[\"buy_count\"] / df_train[\"total_events\"]\n",
        "    df_train[\"add_cart_ratio\"] = df_train[\"add_cart_count\"] / df_train[\"total_events\"]\n",
        "    df_train[\"view_ratio\"] = df_train[\"view_count\"] / df_train[\"total_events\"]\n",
        "    df_train[\"remove_cart_ratio\"] = df_train[\"remove_cart_count\"] / df_train[\"total_events\"]\n",
        "\n",
        "    df_train[\"user_past_buy_ratio\"] = df_train[\"user_past_buy_count\"] / df_train[\"user_past_event_count\"]\n",
        "    df_train[\"user_past_add_cart_ratio\"] = df_train[\"user_past_add_cart_count\"] / df_train[\"user_past_event_count\"]\n",
        "    df_train[\"user_past_view_ratio\"] = df_train[\"user_past_view_count\"] / df_train[\"user_past_event_count\"]\n",
        "    df_train[\"user_past_remove_cart_ratio\"] = df_train[\"user_past_remove_cart_count\"] / df_train[\"user_past_event_count\"]\n",
        "\n",
        "    df_train[\"session_duration\"] = (df_train[\"max_date\"] - df_train[\"min_date\"]).dt.total_seconds() / 86400\n",
        "    df_train[\"last_activity_gap\"] = (df_train[\"min_date\"] - df_train[\"user_last_event_time\"]).dt.total_seconds() / 86400\n",
        "    df_train[\"user_activity_duration\"] = (df_train[\"user_last_event_time\"] - df_train[\"user_first_event_time\"]).dt.total_seconds() / 86400\n",
        "\n",
        "    df_train[\"user_past_session_count_ratio\"] = df_train[\"user_nunique_session\"] / df_train[\"user_past_event_count\"]\n",
        "    df_train[\"user_past_session_time_ratio\"] = df_train[\"user_nunique_session\"] / (df_train[\"user_activity_duration\"]+1e-6)\n",
        "    df_train[\"user_past_event_time_ratio\"] = df_train[\"user_past_event_count\"] / (df_train[\"user_activity_duration\"]+1e-6)\n",
        "\n",
        "    df_train[\"event_frequency\"]= df_train['total_events'] / (df_train[\"session_duration\"] + 1e-6)\n",
        "\n",
        "    return df_train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02f3b6f2",
      "metadata": {
        "id": "02f3b6f2"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06da87c6",
      "metadata": {
        "id": "06da87c6"
      },
      "outputs": [],
      "source": [
        "df_train = (\n",
        "    train.groupby(\"user_session\")\n",
        "            .agg(\n",
        "                min_date=(\"event_time\", \"min\"),\n",
        "                max_date=(\"event_time\", \"max\"),\n",
        "                user_id=(\"user_id\", \"first\"),\n",
        "                session_value=(\"session_value\", \"first\"),\n",
        "                buy_count=(\"event_type\", lambda x: (x == \"BUY\").sum()),\n",
        "                add_cart_count=(\"event_type\", lambda x: (x == \"ADD_CART\").sum()),\n",
        "                view_count=(\"event_type\", lambda x: (x == \"VIEW\").sum()),\n",
        "                remove_cart_count=(\"event_type\", lambda x: (x == \"REMOVE_CART\").sum()),\n",
        "                total_events=(\"event_time\", \"count\"),\n",
        "\n",
        "                unique_product_count = (\"product_id\", \"nunique\"),\n",
        "                top_product_count = (\"product_id\", lambda x: x.value_counts().iloc[0]),\n",
        "                unique_category_count = (\"category_id\", \"nunique\"),\n",
        "                category_switch_count = (\"category_id\",lambda x: ((x != x.shift(1)) & x.shift(1).notna()).sum()), #kaç kez bir kategoriden diğerine geçilmiş\n",
        "\n",
        "                intra_session_revisit=(\"product_id\",lambda x: x.value_counts().sub(1).clip(lower=0).sum()),\n",
        "\n",
        "                intra_session_category_revisit=(\"category_id\",lambda x: x.value_counts().sub(1).clip(lower=0).sum()),\n",
        "            )\n",
        "            .reset_index()\n",
        "            .assign(\n",
        "            product_per_category = (lambda a: (a[\"unique_product_count\"] / a[\"unique_category_count\"])), #1den büyükse aynı kategoriye ait birden fazla ürün var\n",
        "\n",
        "            #category_entropy product_per_category'ye göre daha kapsamlı bilgi veriyor. (entropy=0 daha kararlı user demek)\n",
        "            category_entropy = lambda a: a['user_session'].map(\n",
        "                train.groupby(['user_session','category_id'])['product_id']\n",
        "                .nunique()  # session bazında kategori başına unique product\n",
        "                .groupby('user_session')\n",
        "                .agg(lambda x: -np.sum((x / x.sum()) * np.log(x / x.sum())))\n",
        "                ).clip(lower=0) # -0 değerleri geliyordu o yüzden ekledim (başka negatif değer gelmiyordu)\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "188cb516",
      "metadata": {
        "id": "188cb516"
      },
      "outputs": [],
      "source": [
        "event_per_product = (\n",
        "    train.groupby([\"user_session\", \"product_id\"])[\"event_type\"]\n",
        "    .nunique()\n",
        "    .reset_index(name=\"unique_event_count\")\n",
        ")\n",
        "\n",
        "# session bazında mono/duo/trio/tetra sayıları\n",
        "mono_duo_counts = (\n",
        "    event_per_product.groupby(\"user_session\")[\"unique_event_count\"]\n",
        "    .value_counts()\n",
        "    .unstack(fill_value=0)\n",
        "    .rename(columns={\n",
        "        1: \"session_product_mono_count\",\n",
        "        2: \"session_product_duo_count\",\n",
        "        3: \"session_product_trio_count\",\n",
        "        4: \"session_product_tetra_count\"\n",
        "    })\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "df_train = df_train.merge(mono_duo_counts, on=\"user_session\", how=\"left\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9af7e32e",
      "metadata": {
        "id": "9af7e32e"
      },
      "outputs": [],
      "source": [
        "df_train[\"user_last_event_time\"] = pd.NaT\n",
        "df_train[\"user_last_event_time\"] = (\n",
        "    df_train[\"user_last_event_time\"]\n",
        "    .astype(\"datetime64[ns]\")\n",
        "    .dt.tz_localize(\"UTC\")\n",
        ")\n",
        "\n",
        "df_train[\"user_first_event_time\"] = pd.NaT\n",
        "df_train[\"user_first_event_time\"] = (\n",
        "    df_train[\"user_first_event_time\"]\n",
        "    .astype(\"datetime64[ns]\")\n",
        "    .dt.tz_localize(\"UTC\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27bc3f6b",
      "metadata": {
        "id": "27bc3f6b"
      },
      "outputs": [],
      "source": [
        "for id,row in df_train.iterrows():\n",
        "    selected = train[ (train[\"user_id\"]==row[\"user_id\"]) & (train[\"event_time\"]<row[\"min_date\"]) ]\n",
        "\n",
        "    df_train.loc[id, \"user_past_event_count\"] = len(selected)\n",
        "    df_train.loc[id, \"user_past_add_cart_count\"] = (selected[\"event_type\"] == \"ADD_CART\").sum()\n",
        "    df_train.loc[id, \"user_past_view_count\"] = (selected[\"event_type\"] == \"VIEW\").sum()\n",
        "    df_train.loc[id, \"user_past_buy_count\"] = (selected[\"event_type\"] == \"BUY\").sum()\n",
        "    df_train.loc[id, \"user_past_remove_cart_count\"] = (selected[\"event_type\"] == \"REMOVE_CART\").sum()\n",
        "\n",
        "    df_train.loc[id, \"user_nunique_session\"] = selected[\"user_session\"].nunique()\n",
        "    df_train.loc[id, \"user_nunique_product\"] = selected[\"product_id\"].nunique()\n",
        "    df_train.loc[id, \"user_nunique_category\"] = selected[\"category_id\"].nunique()\n",
        "    df_train.loc[id, \"user_last_event_time\"] = selected[\"event_time\"].max()\n",
        "    df_train.loc[id, \"user_first_event_time\"] = selected[\"event_time\"].min()\n",
        "\n",
        "    # inter-session revisit count\n",
        "    product_counts = selected['product_id'].value_counts()\n",
        "    revisit_count = (product_counts.sub(1).clip(lower=0)).sum()\n",
        "    df_train.loc[id, 'inter_session_revisit'] = revisit_count\n",
        "\n",
        "    # Inter-session category revisit count\n",
        "    category_counts = selected['category_id'].value_counts()\n",
        "    inter_session_category_count = (category_counts.sub(1).clip(lower=0)).sum()\n",
        "    df_train.loc[id, 'inter_session_category_count'] = inter_session_category_count\n",
        "\n",
        "    event_per_product = selected.groupby(\"product_id\")[\"event_type\"].nunique().value_counts()\n",
        "    df_train.loc[id, \"user_past_product_mono_count\"] = event_per_product.get(1, 0)\n",
        "    df_train.loc[id, \"user_past_product_duo_count\"] = event_per_product.get(2, 0)\n",
        "    df_train.loc[id, \"user_past_product_trio_count\"] = event_per_product.get(3, 0)\n",
        "    df_train.loc[id, \"user_past_product_tetra_count\"] = event_per_product.get(4, 0)\n",
        "\n",
        "    event_per_category = selected.groupby(\"category_id\")[\"event_type\"].nunique().value_counts()\n",
        "    df_train.loc[id, \"user_past_category_mono_count\"] = event_per_category.get(1, 0)\n",
        "    df_train.loc[id, \"user_past_category_duo_count\"] = event_per_category.get(2, 0)\n",
        "    df_train.loc[id, \"user_past_category_trio_count\"] = event_per_category.get(3, 0)\n",
        "    df_train.loc[id, \"user_past_category_tetra_count\"] = event_per_category.get(4, 0)\n",
        "\n",
        "    df_train.loc[id, \"past_value_sum\"] = (selected.drop_duplicates(subset=\"user_session\")[\"session_value\"].sum())\n",
        "    df_train.loc[id, \"past_value_mean\"] = (selected.drop_duplicates(subset=\"user_session\")[\"session_value\"].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41ca114e",
      "metadata": {
        "id": "41ca114e"
      },
      "outputs": [],
      "source": [
        "df_train = extract_features(df_train)\n",
        "df_train = extract_datetime_features(df_train,[\"min_date\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a2c7819",
      "metadata": {
        "id": "3a2c7819"
      },
      "outputs": [],
      "source": [
        "df_train = df_train.drop([\"user_last_event_time\",\"user_first_event_time\"],axis=1)\n",
        "df_train = df_train[ (df_train[\"user_session\"] != \"SESSION_000000\") | (df_train[\"user_session\"] != \"SESSION_020888\") ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35a7ebb4",
      "metadata": {
        "id": "35a7ebb4"
      },
      "outputs": [],
      "source": [
        "columns_0= [\"user_activity_duration\",\"user_past_event_time_ratio\",\"user_past_session_time_ratio\",\"user_past_session_count_ratio\",\n",
        "           \"user_past_remove_cart_ratio\",\"user_past_view_ratio\",\"user_past_add_cart_ratio\",\"user_past_buy_ratio\",\"category_entropy\",\"past_value_mean\"]\n",
        "columns_99= [\"last_activity_gap\"]\n",
        "for i in columns_0:\n",
        "    df_train[i] = df_train[i].fillna(0)\n",
        "for i in columns_99:\n",
        "    df_train[i] = df_train[i].fillna(999)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cd0f3ca",
      "metadata": {
        "id": "8cd0f3ca"
      },
      "outputs": [],
      "source": [
        "df_train.to_csv(\"train_final.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce5b78ee",
      "metadata": {
        "id": "ce5b78ee",
        "outputId": "0925ba3d-8854-4e97-e234-9e6b00c1b7cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(70736, 78)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1e03b51",
      "metadata": {
        "id": "b1e03b51"
      },
      "outputs": [],
      "source": [
        "del df_train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b23c3db1",
      "metadata": {
        "id": "b23c3db1"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48bc5866",
      "metadata": {
        "id": "48bc5866"
      },
      "outputs": [],
      "source": [
        "df_test = (\n",
        "    test.groupby(\"user_session\")\n",
        "            .agg(\n",
        "                min_date=(\"event_time\", \"min\"),\n",
        "                max_date=(\"event_time\", \"max\"),\n",
        "                user_id=(\"user_id\", \"first\"),\n",
        "                buy_count=(\"event_type\", lambda x: (x == \"BUY\").sum()),\n",
        "                add_cart_count=(\"event_type\", lambda x: (x == \"ADD_CART\").sum()),\n",
        "                view_count=(\"event_type\", lambda x: (x == \"VIEW\").sum()),\n",
        "                remove_cart_count=(\"event_type\", lambda x: (x == \"REMOVE_CART\").sum()),\n",
        "                total_events=(\"event_time\", \"count\"),\n",
        "\n",
        "                unique_product_count = (\"product_id\", \"nunique\"),\n",
        "                top_product_count = (\"product_id\", lambda x: x.value_counts().iloc[0]),\n",
        "                unique_category_count = (\"category_id\", \"nunique\"),\n",
        "                category_switch_count = (\"category_id\",lambda x: ((x != x.shift(1)) & x.shift(1).notna()).sum()), #kaç kez bir kategoriden diğerine geçilmiş\n",
        "\n",
        "                intra_session_revisit=(\"product_id\",lambda x: x.value_counts().sub(1).clip(lower=0).sum()),\n",
        "\n",
        "                intra_session_category_revisit=(\"category_id\",lambda x: x.value_counts().sub(1).clip(lower=0).sum()),\n",
        "            )\n",
        "            .reset_index()\n",
        "            .assign(\n",
        "            product_per_category = (lambda a: (a[\"unique_product_count\"] / a[\"unique_category_count\"])), #1den büyükse aynı kategoriye ait birden fazla ürün var\n",
        "\n",
        "            #category_entropy product_per_category'ye göre daha kapsamlı bilgi veriyor. (entropy=0 daha kararlı user demek)\n",
        "            category_entropy = lambda a: a['user_session'].map(\n",
        "                train.groupby(['user_session','category_id'])['product_id']\n",
        "                .nunique()  # session bazında kategori başına unique product\n",
        "                .groupby('user_session')\n",
        "                .agg(lambda x: -np.sum((x / x.sum()) * np.log(x / x.sum())))\n",
        "                ).clip(lower=0) # -0 değerleri geliyordu o yüzden ekledim (başka negatif değer gelmiyordu)\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f5d6770",
      "metadata": {
        "id": "5f5d6770"
      },
      "outputs": [],
      "source": [
        "event_per_product = (\n",
        "    test.groupby([\"user_session\", \"product_id\"])[\"event_type\"]\n",
        "    .nunique()\n",
        "    .reset_index(name=\"unique_event_count\")\n",
        ")\n",
        "\n",
        "# session bazında mono/duo/trio/tetra sayıları\n",
        "mono_duo_counts = (\n",
        "    event_per_product.groupby(\"user_session\")[\"unique_event_count\"]\n",
        "    .value_counts()\n",
        "    .unstack(fill_value=0)\n",
        "    .rename(columns={\n",
        "        1: \"session_product_mono_count\",\n",
        "        2: \"session_product_duo_count\",\n",
        "        3: \"session_product_trio_count\",\n",
        "        4: \"session_product_tetra_count\"\n",
        "    })\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "df_test = df_test.merge(mono_duo_counts, on=\"user_session\", how=\"left\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e26dea7",
      "metadata": {
        "id": "4e26dea7"
      },
      "outputs": [],
      "source": [
        "df_test[\"user_last_event_time\"] = pd.NaT\n",
        "df_test[\"user_last_event_time\"] = (\n",
        "    df_test[\"user_last_event_time\"]\n",
        "    .astype(\"datetime64[ns]\")\n",
        "    .dt.tz_localize(\"UTC\")\n",
        ")\n",
        "\n",
        "df_test[\"user_first_event_time\"] = pd.NaT\n",
        "df_test[\"user_first_event_time\"] = (\n",
        "    df_test[\"user_first_event_time\"]\n",
        "    .astype(\"datetime64[ns]\")\n",
        "    .dt.tz_localize(\"UTC\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9fc940e",
      "metadata": {
        "id": "d9fc940e"
      },
      "outputs": [],
      "source": [
        "for id,row in df_test.iterrows():\n",
        "    selected = pd.concat([\n",
        "        train[train[\"user_id\"] == row[\"user_id\"]],\n",
        "        test[(test[\"user_id\"] == row[\"user_id\"]) & (test[\"event_time\"] < row[\"min_date\"])]\n",
        "    ], ignore_index=True)\n",
        "\n",
        "    df_test.loc[id, \"user_past_event_count\"] = len(selected)\n",
        "    df_test.loc[id, \"user_past_add_cart_count\"] = (selected[\"event_type\"] == \"ADD_CART\").sum()\n",
        "    df_test.loc[id, \"user_past_view_count\"] = (selected[\"event_type\"] == \"VIEW\").sum()\n",
        "    df_test.loc[id, \"user_past_buy_count\"] = (selected[\"event_type\"] == \"BUY\").sum()\n",
        "    df_test.loc[id, \"user_past_remove_cart_count\"] = (selected[\"event_type\"] == \"REMOVE_CART\").sum()\n",
        "\n",
        "    df_test.loc[id, \"user_nunique_session\"] = selected[\"user_session\"].nunique()\n",
        "    df_test.loc[id, \"user_nunique_product\"] = selected[\"product_id\"].nunique()\n",
        "    df_test.loc[id, \"user_nunique_category\"] = selected[\"category_id\"].nunique()\n",
        "    df_test.loc[id, \"user_last_event_time\"] = selected[\"event_time\"].max()\n",
        "    df_test.loc[id, \"user_first_event_time\"] = selected[\"event_time\"].min()\n",
        "\n",
        "    # inter-session revisit count\n",
        "    product_counts = selected['product_id'].value_counts()\n",
        "    revisit_count = (product_counts.sub(1).clip(lower=0)).sum()\n",
        "    df_test.loc[id, 'inter_session_revisit'] = revisit_count\n",
        "\n",
        "    # Inter-session category revisit count\n",
        "    category_counts = selected['category_id'].value_counts()\n",
        "    inter_session_category_count = (category_counts.sub(1).clip(lower=0)).sum()\n",
        "    df_test.loc[id, 'inter_session_category_count'] = inter_session_category_count\n",
        "\n",
        "    event_per_product = selected.groupby(\"product_id\")[\"event_type\"].nunique().value_counts()\n",
        "    df_test.loc[id, \"user_past_product_mono_count\"] = event_per_product.get(1, 0)\n",
        "    df_test.loc[id, \"user_past_product_duo_count\"] = event_per_product.get(2, 0)\n",
        "    df_test.loc[id, \"user_past_product_trio_count\"] = event_per_product.get(3, 0)\n",
        "    df_test.loc[id, \"user_past_product_tetra_count\"] = event_per_product.get(4, 0)\n",
        "\n",
        "    event_per_category = selected.groupby(\"category_id\")[\"event_type\"].nunique().value_counts()\n",
        "    df_test.loc[id, \"user_past_category_mono_count\"] = event_per_category.get(1, 0)\n",
        "    df_test.loc[id, \"user_past_category_duo_count\"] = event_per_category.get(2, 0)\n",
        "    df_test.loc[id, \"user_past_category_trio_count\"] = event_per_category.get(3, 0)\n",
        "    df_test.loc[id, \"user_past_category_tetra_count\"] = event_per_category.get(4, 0)\n",
        "\n",
        "    df_test.loc[id, \"past_value_sum\"] = (selected.drop_duplicates(subset=\"user_session\")[\"session_value\"].sum())\n",
        "    df_test.loc[id, \"past_value_mean\"] = (selected.drop_duplicates(subset=\"user_session\")[\"session_value\"].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffec99a8",
      "metadata": {
        "id": "ffec99a8"
      },
      "outputs": [],
      "source": [
        "df_test = extract_features(df_test)\n",
        "df_test = extract_datetime_features(df_test,[\"min_date\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "973c9662",
      "metadata": {
        "id": "973c9662"
      },
      "outputs": [],
      "source": [
        "df_test = df_test.drop([\"user_last_event_time\",\"user_first_event_time\"],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "306c2b1a",
      "metadata": {
        "id": "306c2b1a"
      },
      "outputs": [],
      "source": [
        "columns_0= [\"user_activity_duration\",\"user_past_event_time_ratio\",\"user_past_session_time_ratio\",\"user_past_session_count_ratio\",\n",
        "           \"user_past_remove_cart_ratio\",\"user_past_view_ratio\",\"user_past_add_cart_ratio\",\"user_past_buy_ratio\",\"category_entropy\"]\n",
        "columns_99= [\"last_activity_gap\"]\n",
        "for i in columns_0:\n",
        "    df_test[i] = df_test[i].fillna(0)\n",
        "for i in columns_99:\n",
        "    df_test[i] = df_test[i].fillna(999)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e41f2211",
      "metadata": {
        "id": "e41f2211"
      },
      "outputs": [],
      "source": [
        "df_test.to_csv(\"test_final.csv\",index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.12.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}